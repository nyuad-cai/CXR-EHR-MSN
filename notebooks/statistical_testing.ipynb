{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.stats import permutation_test # requires python 3.8 and updated scipy version\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import permutation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.permutation_test.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Permutation_test\n",
    "\n",
    "https://nblok306.ftn.uns.ac.rs/~zoran/A/knjige/Chihara2011.pdf\n",
    "\n",
    "https://matthew-brett.github.io/cfd2020/permutation/permutation_and_t_test.html\n",
    "\n",
    "https://www.amazon.com/exec/obidos/ASIN/0943126444/jmir-20?dev-t=mason-wrapper%26camp=2025%26link_code=xm2\n",
    "\n",
    "https://support.jmir.org/hc/en-us/articles/360000002012\n",
    "\n",
    "https://github.com/qbarthelemy/PyPermut\n",
    "\n",
    "\n",
    "- Null hypothesis: Two samples belong to the same distribution\n",
    "\n",
    "- Alternative hypothesis: Model B (ML model) performs better than Model A (NEWS)\n",
    "\n",
    "We will compute the p-value based on the differences between the samples. The p-value indicates the probability that pure chance would lead to the same observed difference between the two samples. If the p-value is below a certain threshold assumed to be statistically significant, then we reject the null hypothesis and accept the alternative hypothesis. If the p-value is above the threshold, then we cannot reject the null hypothesis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Simulate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# Create a sample of groundtruth labels\n",
    "y = [1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,]\n",
    "\n",
    "# Simulate predictions of model A (Assume NEWS)\n",
    "y_a = [0.8, 0.7, 0.2, 0.8, 0.15, 0.1, 0.2, 0.9, 0.8, 0.7, 0.2, 0.8, 0.15, 0.1, 0.2, 0.9, 0.8, 0.7, 0.2, 0.8, 0.15, 0.1, 0.2, 0.9]\n",
    "auroc_a = metrics.roc_auc_score(y, y_a)\n",
    "print(auroc_a)\n",
    "\n",
    "# Simulate predictions of model B (Assume XGboost)\n",
    "y_b = [0, 0.5, 0.7, 0.9, 0.4, 0.2, 0.02, 0.01, 0, 0.5, 0.7, 0.9, 0.4, 0.2, 0.02, 0.01, 0, 0.5, 0.7, 0.9, 0.4, 0.2, 0.02, 0.01]\n",
    "auroc_b = metrics.roc_auc_score(y, y_b)\n",
    "print(auroc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    Function to seed all RNGs. \n",
    "    Taken from #https://stackoverflow.com/questions/57416925/best-practices-for-generating-a-random-seeds-to-seed-pytorch\n",
    "\n",
    "    Args:\n",
    "        seed: RNG seed. Defaults to 42.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBoost, NEWS, LogisticRegression\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m seed_everything(\u001b[38;5;241m32\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from models import XGBoost, NEWS, LogisticRegression\n",
    "\n",
    "path = './results/'\n",
    "\n",
    "seed_everything(32)\n",
    "\n",
    "# with open(path + '/targets.pkl', 'rb') as f:\n",
    "#     targets = pickle.load(f)\n",
    "labely = ['y_true']\n",
    "\n",
    "# train = pd.read_csv(path + '/train' + '.csv', encoding=\"ISO-8859-1\")\n",
    "# val = pd.read_csv(path + '/val' + '.csv', encoding=\"ISO-8859-1\")\n",
    "test = pd.read_csv('splits/testH24' + '.csv', encoding=\"ISO-8859-1\")\n",
    "\n",
    "# X_train = train[targets]\n",
    "# y_train = train[labely]\n",
    "# X_val = val[targets]\n",
    "# y_val = val[labely]\n",
    "# X_test= test[targets]\n",
    "# y_test= test[labely]\n",
    "\n",
    "# X_train_col_mean = np.nanmean(X_train, axis=0)\n",
    "# X_val_col_mean = np.nanmean(X_val, axis=0)\n",
    "# X_test_col_mean = np.nanmean(X_val, axis=0)\n",
    "\n",
    "# X_train = np.where(np.isnan(X_train), X_train_col_mean, X_train)\n",
    "# X_val = np.where(np.isnan(X_val), X_val_col_mean, X_val)\n",
    "# X_test = np.where(np.isnan(X_test), X_test_col_mean, X_test)\n",
    "\n",
    "\n",
    "# Create a sample of groundtruth labels\n",
    "y = test[labely]\n",
    "y = y.values[:,0]\n",
    "\n",
    "metric = 'auprc'\n",
    "\n",
    "# modelA = LogisticRegression()\n",
    "# modelA.train(X_train, y_train, X_val, y_val, metric='auprc')\n",
    "#Simulate predictions of model A (Assume NEWS)\n",
    "with open(path + \"newsH24.pkl\", \"rb\") as f:\n",
    "    y_a = pickle.load(f)\n",
    "#y_a = modelA.model.predict_proba(X_test)[:,1]\n",
    "auroc_a = metrics.roc_auc_score(y, y_a)\n",
    "print(auroc_a)\n",
    "\n",
    "\n",
    "with open(path + \"fcnnH24.pkl\", \"rb\") as f:\n",
    "    y_b = pickle.load(f)\n",
    "auroc_b = metrics.roc_auc_score(y, y_b)\n",
    "print(auroc_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Calculate confidence intervals for metric using the bootstrap method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap(y_true, y_pred, metric='auroc'):\n",
    "    n_iterations = 1000\n",
    "    Test_AUC=[]\n",
    "    Test_AUPRC=[]\n",
    "\n",
    "    if metric == 'auroc':\n",
    "        score = roc_auc_score\n",
    "    else:\n",
    "        score = average_precision_score\n",
    "    auc_true = score(y_true, y_pred)\n",
    "#     AUPRC_true = average_precision_score(test[outcome],predictions_df[\"avg\"])\n",
    "    \n",
    "    test = pd.DataFrame({'y': y_true, 'pred': y_pred})\n",
    "\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        test_resampled = test.sample(frac=1, replace=True)\n",
    "\n",
    "        auc = score(test_resampled['y'], test_resampled['pred'])\n",
    "        Test_AUC.append(auc)\n",
    "        #avg = average_precision_score(test_resampled[outcome], test_resampled[\"prediction\"])\n",
    "        #Test_AUPRC.append(avg)\n",
    "\n",
    "    return Test_AUC, auc_true\n",
    "\n",
    "\n",
    "def compute_confidence_intervals(list_,true_value):\n",
    "    \"\"\"This function calcualted the 95% Confidence Intervals\"\"\"\n",
    "    delta = (true_value - list_)\n",
    "    list(np.sort(delta))\n",
    "    delta_lower = np.percentile(delta, 97.5)\n",
    "    delta_upper = np.percentile(delta, 2.5)\n",
    "\n",
    "    upper = true_value - delta_upper\n",
    "    lower = true_value - delta_lower\n",
    "    print(f\"CI 95% {round(true_value, 3)} ( {round(lower, 3)} , {round(upper, 3)} )\")\n",
    "\n",
    "    return(upper,lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boostrap model A\n",
    "test_auc_A, auc_true_A = boostrap(y, y_a, metric=metric)\n",
    "\n",
    "# bootstrap model B\n",
    "test_auc_B, auc_true_B = boostrap(y, y_b, metric=metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI 95% 0.133 ( 0.117 , 0.152 )\n"
     ]
    }
   ],
   "source": [
    "upp_a, lower_a = compute_confidence_intervals(test_auc_A, auc_true_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI 95% 0.2 ( 0.178 , 0.225 )\n"
     ]
    }
   ],
   "source": [
    "upp_b, lower_b = compute_confidence_intervals(test_auc_B, auc_true_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Compute the difference between the two samples using boostrapping + CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostrap_diff(y_true, y_pred_A, y_pred_B, metric = 'auroc'):\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    Test_AUC_diff=[]\n",
    "    \n",
    "    test = pd.DataFrame({'y': y_true, 'pred_A': y_pred_A, 'pred_B': y_pred_B})\n",
    "\n",
    "    if metric == 'auroc':\n",
    "        score = roc_auc_score\n",
    "    else:\n",
    "        score = average_precision_score\n",
    "    \n",
    "    auc_true_A = score(y_true, y_pred_A)\n",
    "    auc_true_B = score(y_true, y_pred_B)\n",
    "\n",
    "    auroc_diff = auc_true_B - auc_true_A \n",
    "\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        test_resampled = test.sample(frac=1, replace=True)\n",
    "\n",
    "        auc_A = score(test_resampled['y'], test_resampled['pred_A'])\n",
    "        auc_B = score(test_resampled['y'], test_resampled['pred_B'])\n",
    "        \n",
    "        diff = auc_B - auc_A\n",
    "        \n",
    "        Test_AUC_diff.append(diff)\n",
    "\n",
    "    return Test_AUC_diff, auroc_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI 95% 0.067 ( 0.052 , 0.085 )\n"
     ]
    }
   ],
   "source": [
    "# Compute the difference in AUROC and CI for the two samples using the boostrap method\n",
    "test_diff, true_diff =  boostrap_diff(y, y_a, y_b, metric=metric)\n",
    "upp_diff, lower_diff = compute_confidence_intervals(test_diff, true_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] P-value using one-sided permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the two samples\n",
    "pooled_pred = np.append(y_a, y_b)\n",
    "pooled_true = np.append(y, y)\n",
    "\n",
    "n_iters = 10000\n",
    "fake_differences = np.zeros(n_iters)\n",
    "\n",
    "if metric == 'auroc':\n",
    "    score = roc_auc_score\n",
    "else:\n",
    "    score = average_precision_score\n",
    "\n",
    "for i in np.arange(n_iters):\n",
    "    #print(i)\n",
    "    # Obtain permutation for both predictions and groundtruth labels\n",
    "    perm = permutation(len(pooled_pred))\n",
    "    y_true = pooled_true[perm]\n",
    "    y_pred = pooled_pred[perm]\n",
    "    \n",
    "    # Compute the difference and add it to the array of differences\n",
    "    fake_differences[i] = score(y_true[:len(y_a)], y_pred[:len(y_a)]) - score(y_true[len(y_a):], y_pred[len(y_a):])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sampling distribution of difference of metric')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fake_differences)\n",
    "plt.title('Sampling distribution of difference of metric')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutation_p = np.count_nonzero(\n",
    "    fake_differences >= true_diff)/ n_iters\n",
    "permutation_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0673334121613623"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chexmsn-env\n",
   "language": "python",
   "name": "chexmsn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f7be9d51035affafb29dceabe234970f757e220d15705efccd7c466e6060a35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
